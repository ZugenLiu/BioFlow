Add Nelfanavir test

Even if the tools described in the previous chapter enable us to predict the most likely patwhay by which a secodnary effect is acting, we are much more looking into 

- Technical difficulties
  - neo4j + bulbs => transition towards a Titan DB (neo4j supports only 32G or links nodes at most )
  - scipy/scikit.sparse
  - MongoDB

- Reactiome Parsing, Ehits
  - expected format outline, expected from the BioPax format:
	Fragment@Instance{PartOfComplex:****,localized:***, Modification:***}@MetaObject

  - Pre-parse generation
  - Possible linages typings
  - problems with data typings, data consistency and finally the details about some of the most critical proteins that are not linked correctly

  - Ehits ressource description

  - Purification of the Network by random matrix theory clustering? [HIV publication, protein evolution publication, ...] Principle: retrieve the random matrix values for a provided random matrix with the standard bounds on random matrix eigenvalues, retrieve the matrix and the eigenvectors to which the largest eigenvectors are associated. Project the matrix into this space and perform the clustering in the linear space generated by those matrixes. => provided high confidence of the source data, this method was omited, yet should definetely be used in less uniform matrixes.

  - Improvement of the original Missiuro algorithm 
	Use of computationally more stable Cholesky decompostion istead of LU decomposition, provided that the resistance matrix is positive definite by construction. Computationally less more stable, even if a small perturbation of the matrix is required in order to get rid of the single positive eigenvalue of the matrix (the sum of all the base vectors). This is usefull from the perspective of inexistence of an overloaded solution within the matrix.

	=> more rapid calculation of the information flow. Isntead of N cholesky decompostions, only one is required. This is needed to make the matrix invertible and actually allow the efficient solution of differential equation


  - Intergration of the 
  - Overall information circulation
  - GO-specific information circulation
In fact, with our loaded dataset, even if we are to proceed just 5000 Uniprot-bound proteins, we have to deal with over 2.5*10^7 one to one flow computations, which is rather impressing, even for a very rapid solution of a partial differential equation

Connexion with the previous method not implemented, but scheduled. Because of the difference in the data format syncing, a direct transfert of the informativity was impossible.

Goals: 
 - P. Silver's treaty about the decay of informativity with distance: same would be expected in the case of the of a well-defined graph topology
	=> remarks results were attempted to be reproduced as a part of Hatzimanticatis' course, but only 4000 nodes and 8000 relations led to the breakdown of the method 
 - Reproduce Overington's dataset of the protein targets for the approved drugs
 - include the information


=> Alteranative application: use Humsavar to trace back the Human Polymorphism and disease-related mutations onto the informativity table and verify the points of convergence of the perturbations

=> Load the PDB data regarding protein domains and points of protein-protein interaction, project them onto the relevant proteins from the UNIPROT

=> eHiTs protein-protein interaction network.

TODO before presentation
=> verify the list of human essential genes
=> Add the true network-based GO genes circulation to the informativity flow calcylation
=> 
