Finally, some of the targets were not studied enough to be sufficiently annotated. Since protein interaction and effect network has the same properties as social graphs, i.e. are small-world networks with power-law distribution, we can estimate if the proteins were sufficiently studied by investigating the overall informativity of their annotation. As long as Zimpf law is followed, we can safely consider that the proteins were sufficiently studied. If we compute the cummulative informativity of expanded GO annotation, we can see that within the human metabolome, from the 18292 human proteins posessing a GO annotation [Graph here], only 8000 follow approimatively a Zimpf distribution and can thus be used for the actual information circulation computation. A more detailed table for 50 proteins with the highest GO annotation informativity in humans can be found in the Annex III.

Once we have filtered out the unsufficiently studied targets, we can pass to the computation of several characteristics of the targets similarities in the GO annotation space. In order to be able to predict the mechanisms of drug secondary effects based on the off-target action of group of drugs sharing the same secondary effect, we would need to be able to detect what GO terms characterise the best the similarities in biological functions between the groups of off-targets affected by different drugs with the same secondary effect. In addition to that, provided that the secondary effects might be due to several distinct mechanisms of action, several of which might be affected by a single drug, we would also like to compute the functional similarity between two targets and the most informative common set of terms that charecterise a group of targets that are functionally similar one to another.

Provided we have expanded GO annotations for each potentially affected target, we can do all of these three tasks easily. For the sake of simplicity, let's start with the simplest case, where we have to deal with only two targets [Figure 9]. We attribute to the first target a positive voltage, proportional to the importance this target has (for instance indicating how strongly this target is inhibited). We attribute the the second target a negative voltage, also proprotional to the importance of this target. Finally we connect each target with all the GO terms from the expanded annotation set that describes it and attribute to each GO a conductance that is proportional to it's informativity. Now, by applying the Kirchoff's law we see that [Math here, current through each GO]. The total circulation of informativity between the targets is [Math here, sum intensities], which is proportional to both the informativity and the number of different GO targets uniting all the terms. 

This way the terms with the highest information flow are the most informative common terms and the total flow between targets is proportional to the flow of information between the targets. However, provided how different the terms are in extensiveness and precision of annotation, we cannot compare directly the raw information flows between the targets. Instead, we normalize the levels of similariteis by dividing the information flow between two targets by the maximal flow there could be, if all the GO terms present in expanded annotations of the two targest were connected to the current source and sink at a given voltage. Thus the information flow between two tagets becomes [Math here]

The computation of the most informative and similar terms for a set of proteins or two sets of proteins happens in a similar fashion. For the computation of the most similar GO terms between the set of two proteins, we simply perform the procedure described above over each pair of proteins [figure 10], each proteins drawn from a different set and divide the resulting information flow through each GO term by the number of pairs. This way, the information flow through each GO term is equal to [Math here], where [explicit math notations]. For the computation of the most informative common GO terms for one single set, we simply perform the same procedure as for information circulation between to sets, except that the second set contains only one node, which is connected to every GO term a node from the first set is connected to. All the code regarding the execution of this algorithm is in the GOInfoCirculation.GOInfoCirculation.py module.

This procedure in itself allows to retrieve some interesting trends regarding the drugs off-target effects. In [Figure 11], you can see the raw output of the method as it was developed during the DrugDesignTech internship for cirrhosis secondary effect. We can find in it some mechansism that are known to contribute to cirrhosis, but unfortunately there seems to be several distinct mechanisms leading to cirrhosis, so the mechanisms of secondary effect action get diluted in the mass of common, yet not very meaningful GO terms. In order to mediate this effect, we would like to cluster off-targets and drugs according to their functional similarity in order to retrieve distinct mechanisms of action and the groups of drugs that have a similar mechanism of action. Experiences with real datasets at DrugDesignTech have shown that the interest of clustering drugs according to the functional similarity  of their off-targets gave little insight into the mechanisms behind the secondary effects, unlike target clustering. Thus the UCSD implemetation included only clustering drugs according to their similarity.

Several approaches were considered the drug clustering according to their similarity:

  - Markov Clustering, based on the eigenvalues and eigenvectors => more efficient way of the random walk (equally known as pagerank, base algorithm for Google), works well for quite extensive graph, based on the  [Enright2002]. Unfortunately a little bit hard to explain and implement extensive linear algebra, plus several parameters that should be hand-picked (inflation and deflation coefficients). Idea behind: perform simultaneous random walk starting from every node, last k steps (take kth power of the transition matrix), then decrease the correlation possibilities for the most improbable transitions (raise each column to the power k, then renormalize) and continue until the algorithm converges towards a stable matrix (each element will have a non-null transition towards the other elements in the set).

Problem: Linear algebra apocalypsis for large connex ghraps: initially sparse matrix can become VERY unsparse after just a couple of iterations (Handshaking theorem). If our matrix has anything over 10k elements (easy with reactome.org computation), we'll need a pretty impressive amount of RAM to run the computation, without speaking about the complexity due to the mutliplication of large dense matrixes. However, in our small targets set this algorithm can be quite interesting.

  - Strongly connex subgraph clustering: [Hervut1999]. The idea is to fragment the graph until we have a set of disconnected stronly connex graphs. Tested at DrugDesignTech, it worked rather well but NP complex if deterministic (twice exponential in case of naive implementation), making it prohibitive for anywhere over 15 targets.

  - BEA clustering (commonly used for geographical SQL database distribution), very efficient and rapid, even for large graphs [King1980]. In this algorithm, we split the matrix into columns, then create a new matrix and add the colums from the inital matrix one after another, disposing them in the way that maximizes the scalar product of two neighbouring columns. We are sure that this algorithm will give the optimal, i.e. put the most correlated columns next one to another, that it will terminate in O(N^2). After that, we rearrange lines so that they follow the columns arrangement. We then compute the binding energy between the columns and split the table along the points of the least binding energy (in our case, 20% of least connected edges were broken, leadin to the emergence of a strongly connex cluster higlighted in red [figure???])

BEA was picked up as the most rapind and most straightforward to implement. All the code regarding the execution of this algorithm is in the GOInfoCirculation.NumpyMatrixOperations.py module.

Once the fragmetnation according into the clusters of functionally similar targets is retrieved, for each cluster of targets, ponderated most important GO terms is calculated. The results of this computations can be seen in Figures [??] for the DrugDesignTech implementation and in Figure [??] For the UCSD implemetation.

The validity of predictions was later verified with the help of experts at DrugDesignTech and by litterature analysis at UCSD. Pure biology not being the main target of this master internship, the verification just attempted to find that the targets selected as the most important were in fact important for the secondary effect we selected for test (pancreatitis), and that the mechanisms suggested by the GO terms had anything to do with the secondary effect of interest. Even if these pathways and genes has nothing to do with pancreas at the first sigh, a series of recent papers have linked both the targets and the suggested pathways of action to the pacratitis and pancreatic cancer. Provided the small sample size of drugs and of targets that were significantly enriched as targets of drugs that can generate pancreatitis, this results are very encouraging and confirm the vaildity of the approach, especially in the light of the results already obtained at DrugDesignTech


####################
Once the drugs were grouped according to a secondary effect they shared, a Student T-test was performed over all the targets to eliminate those that were the least likely to be encountered in case of a random sample of drugs was pulled instead of the set of drugs containing a secondary effect. Only the targets for which the T-test (or probability of non-randomness) exceeds a certain threshold (user-defined) are retained and processed further on. On Figures [?? and ??], you can see the exemples of processing of such targets performed in DrugDesignTech implementation and the UCSD implementation.
##############################

# Markov random Network ( ) model extensuion to lead to a complete model of a drug secondary effect action


# Add a Targets partitionning into sets.

# 

# Limitations and remarks


For the ease of debugging and for the use in the drug development context, the method also adds the contributions of individual targets to each of the most important secondary effects.  Get all teh proteins contributing to a GO term and the percentage of contribution of a protein to a given GO term(especially important in case of the weighted contribution of the proteins).

#Model creation and expansion.
In the context of the drug development and predictive drug toxicology, a Markov random model extension and denoizing might need to be performed on the targets leadint to drug toxicity. In fact, if drugs are present in the training set, they have showed a toxicity in humans, which means that they made it at least to the phase I human trials. That means that they are acting mostly on targets that lead to unnoticeable effects in animals, which most likely induces random noize, hiding some targets whose perturbation will lead to the onset of the secondary effect, but that is never affected by the drugs in phase I, provided that if this target is affected, the secondary effect become noticeable in animals without specialized experiments. 

However, it is important to take in account this effect for the toxicology prediction during the drug development. An easy way to do this is to perfrom Markov Random Field denoizing (known in physics as Ising model system annealing). The idea is pretty simple: if a target has lots of it's neighbours that contribute to a secondary effect, it is likely to also contribute to a secondary effect. A more in depth analysis reveals that functional correlation between the targets with the number of steps away from it decays in a fashion that is very similar to the physical systems for which the Ising model have been developed. For the lack of space, Ising model 

 However, In the drug development context, a toxicity 


# GO terms has a conductivity proprtional to their own informativity => correction through a power-factor transformation of informativity: >1: favors informativity over number of similar nodes; <1: favors the number of similar nodes over the informativity.

# add note about the necessity of informativity correction to account for the correlation between the presence of a less genreal and a more general term.

An additional interest of this method of computation of the most informative GO terms is that it accounts for the difference of conficence we might have about a target's affection by a drug and the fact that the GO terms informativities can be easily changed in order te better suite the domain knowledge of the expert using the system. For instance, an immunologists would be more interested in the terms related to the immune system, such as "T-cell apoptosis", whereas a specialist in renal toxicity will be rather interested in terms like "renal sodium ion transport". A more detailed discussion can be found in the "Machine learning" part of the "Possible extensions" chapter.

The choice of the Gene Ontology as the backbone for our applicatione meant that we would be unable to treat the Cytochrome C - associated drug toxicity, provided that a precise knowledge of drug metabolism process would be required ot predict a possible interaction with a specific member of Cytochrome C family memeber and a cytotoicity due to the interaction with this specific CYP. Provided that cytochrome C - related pathways of cytotoxycity were already well studied and tools have been developped to analyse them, we've decided to ignore CYT C - related secondary effects alltogehter.

In the same fashion, Gene Ontology is rather badly suited for the evaluation of secondary effects occuring in the central nervous system or due to the regulation of gene transcription/translation. In fact, provided that a large number of closely related targets with a highly similar annotation could be affected (such as dopamine receptors for instance), it will be hard to retrieve the targets that are contributing to a specific secondary effect because of the noize coming from all the functional similarities between those targets. In the same fashion, the GO lack the indication of specific regions or genes regulated by transcription factors.

